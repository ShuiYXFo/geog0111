{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt='UCL' src=\"images/ucl_logo.png\" align='center'>\n",
    "\n",
    "\n",
    "[<img src=\"images/noun_post_2109127.svg\" width=\"50\" align='right'>](031_Numpy.ipynb)\n",
    "[<img src=\"images/noun_pre_2109128.svg\" width=\"50\" align='right'>](024_Image_display.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 030 NASA MODIS Earthdata\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Purpose \n",
    "\n",
    "In this notebook, we will use high-level codes from `geog0111` to familiarise ourselves with downloading and interpreting NASA MODIS datasets from [`NASA EarthData`](https://urs.earthdata.nasa.gov). We will also be visualising these data in this notebook.\n",
    "\n",
    "We will be **introducing NASA MODIS land products**, and viewing the MODIS LAI product as an example. This notebook should serve as an introduction to accessing similar products from Earthdata.\n",
    "\n",
    "We will use [`pathlib`](https://docs.python.org/3/library/pathlib.html) and the local package [gurlpath](geog0111/gurlpath) derived from [`urlpath`](https://github.com/chrono-meter/urlpath) to open object streams from URLs and files. \n",
    "\n",
    "For further work on NASA datasets, a student might consider using an explicit [API](https://en.wikipedia.org/wiki/Application_programming_interface) to access the data. If all you want is to get hold of some data product for some defined location and time, then you might use an API such as [Appeears](https://lpdaacsvc.cr.usgs.gov/appeears/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "Since the idea of this section is to get used to the datasets, the requirement for coding is quite low. You should have some familiarity with the following:\n",
    "\n",
    "* [001 Using Notebooks](001_Notebook_use.ipynb)\n",
    "* [010 Variables, comments and print()](010_Python_Introduction.ipynb)\n",
    "* [011 Data types](011_Python_data_types.ipynb) \n",
    "* [024 Image display](024_Image_display)\n",
    "\n",
    "### Test\n",
    "\n",
    "You should run a [NASA account test](004_Accounts.ipynb) if you have not already done so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODIS LAI product \n",
    "\n",
    "To introduce geospatial processing, we will use a dataset from the MODIS LAI product over the UK. \n",
    "\n",
    "The data product [MOD15](https://modis.gsfc.nasa.gov/data/dataprod/mod15.php) LAI/FPAR has been generated from NASA MODIS sensors Terra and Aqua data since 2002. We are now in dataset collection 6 (the data version to use).\n",
    "\n",
    "    LAI is defined as the one-sided green leaf area per unit ground area in broadleaf canopies and as half the total needle surface area per unit ground area in coniferous canopies. FPAR is the fraction of photosynthetically active radiation (400-700 nm) absorbed by green vegetation. Both variables are used for calculating surface photosynthesis, evapotranspiration, and net primary production, which in turn are used to calculate terrestrial energy, carbon, water cycle processes, and biogeochemistry of vegetation. Algorithm refinements have improved quality of retrievals and consistency with field measurements over all biomes, with a focus on woody vegetation.\n",
    "    \n",
    "We use such data to map and understand about the dynamics of terrestrial vegetation / carbon, for example, for climate studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raster data are arranged in tiles, indexed by row and column, to cover the globe:\n",
    "\n",
    "\n",
    "![MODIS tiles](https://www.researchgate.net/profile/J_Townshend/publication/220473201/figure/fig5/AS:277546596880390@1443183673583/The-global-MODIS-Sinusoidal-tile-grid.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Exercise 1\n",
    "\n",
    "The pattern on the tile names is `hXXvYY` where `XX` is the horizontal coordinate and `YY` the vertical.\n",
    "\n",
    "\n",
    "* use the map above to work out the names of the two tiles that we will need to access data over the UK\n",
    "* set the variable `tiles` to contain these two names in a list\n",
    "\n",
    "For example, for the two tiles covering Madagascar, we would set:\n",
    "\n",
    "    tiles = ['h22v10','h22v11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# tiles for the UK\n",
    "\n",
    "tiles = ['h17v03', 'h17v04', 'h18v03', 'h18v04']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Accessing NASA MODIS URLs\n",
    "\n",
    "<span class=\"burk\">**Warning: The NASA data servers tend to be down for maintainance on Wednesday morning EST**</span>\n",
    "\n",
    "Although you can access MODIS datasets through the [NASA Earthdata](https://urs.earthdata.nasa.gov/home) interface, there are many occasions that we would want to just automatically pull datasets from a server. As we note above, we could use some existing API for this, such as [Appeears](https://lpdaacsvc.cr.usgs.gov/appeears/), but we are aiming here at being able to ultimately develop codes that do this from a lower-level perspective. \n",
    "\n",
    "Automation has many roles, and is particularly useful when you want a time series of data that might involve many files. For example, for analysing LAI or other variables over space/time) we will want to write code that pulls the time series of data. \n",
    "\n",
    "If you visit the site [https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006](https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006), you will see 'date' style links (e.g. `2018.09.30`) through to sub-directories. \n",
    "\n",
    "In these, e.g. [https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2018.09.30/](https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2018.09.30/) you will find URLs of a set of files. \n",
    "\n",
    "The files pointed to by the URLs are the MODIS MOD15 4-day composite 500 m LAI/FPAR product [MCD15A3H](https://lpdaac.usgs.gov/products/mcd15a3hv006/).\n",
    "\n",
    "There are links to several datasets on the page, including 'quicklook files' that are jpeg format images of the datasets, e.g.:\n",
    "\n",
    "![MCD15A3H.A2018273.h17v03](https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2018.09.30/BROWSE.MCD15A3H.A2018273.h17v03.006.2018278143630.1.jpg)\n",
    "\n",
    "as well as `xml` files and `hdf` datasets. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Products\n",
    "\n",
    "If we look at the dataserver we have specified [https://e4ftl01.cr.usgs.gov](https://e4ftl01.cr.usgs.gov), we will see that a number of sub-directories exist. Each of these 'server directories' points to a different data stream:\n",
    "\n",
    "    [DIR] ASTT/                   2019-08-05 07:54    -   \n",
    "    [DIR] COMMUNITY/              2020-06-02 08:45    -   \n",
    "    [DIR] ECOSTRESS/              2020-04-09 10:30    -   \n",
    "    [DIR] GEDI/                   2020-02-10 09:58    -   \n",
    "    [DIR] MEASURES/               2020-03-17 10:55    -   \n",
    "    [DIR] MOLA/                   2020-06-01 09:20    -   \n",
    "    [DIR] MOLT/                   2020-04-14 08:06    -   \n",
    "    [DIR] MOTA/                   2019-12-27 06:49    -   \n",
    "    [DIR] VIIRS/                  2020-06-23 10:26    -   \n",
    "\n",
    "For example, we might notice [VIIRS](https://e4ftl01.cr.usgs.gov/VIIRS) which takes us to the [VIIRS data products](https://viirsland.gsfc.nasa.gov), or [GEDI](https://e4ftl01.cr.usgs.gov/GEDI) [spaceborne lidar](https://gedi.umd.edu/) data. Each of these data streams will have their own properties that we need to appreciate before using them.\n",
    "\n",
    "### MOTA\n",
    "\n",
    "The URL we have used above, [https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2018.09.30/](https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2018.09.30/) starts with a call to the server directory `MOTA`, so we can think of `https://e4ftl01.cr.usgs.gov/MOTA` as the base level URL.\n",
    "\n",
    "MOTA refers to combined MODIS Terra and Aqua datasets. Similarly, MOLA and MOLT refer to datasets generated from single MODIS sensors of Aqua and Terra, respectively.\n",
    "\n",
    "The rest of the directory information `MCD15A3H.006/2018.09.30` tells us:\n",
    "\n",
    "* the product name `MCD15A3H`\n",
    "* the product version `006`\n",
    "* the date of the dataset `2018.09.30`\n",
    "\n",
    "There are several ways we could specify the date information. The most 'human readable' is probably `YYYY.MM.DD` as given here, but we may also use day of year. Recall from [023 Plotting](023_Plotting.ipynb#datetime) how to convert date formats.\n",
    "\n",
    "We will mainly use [`geog0111.im_display`](geog0111/im_display.py) to do simple image plots. This is essentially the same as the code you have developed in [an exercise](024_Image_display.ipynb#Exercise-2).\n",
    "\n",
    "\n",
    "If we look at the [product specification page](https://lpdaac.usgs.gov/products/mcd15a3hv006/) for `MCD15A3H` we see that the data product has multiple data layers. In the case of MCD15A3H, this is:\n",
    "\n",
    "|SDS Name\t|Description\t| Units\t|Data Type\t|Fill Value|\tNo Data Value\t|Valid Range|\tScale Factor\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|-|\n",
    "| Fpar_500m |\tFraction of Photosynthetically Active Radiation\t|Percent|\t8-bit unsigned integer\t|249 to 255\t|N/A\t|0 to 100\t|0.01\n",
    "|Lai_500m\t|Leaf Area Index|\tm²/m²|\t8-bit unsigned integer|\t249 to 255\t|N/A|\t0 to 100|\t0.1|\n",
    "|FparLai_QC\t|Quality for  FPAR and LAI\t|Class Flag\t|8-bit unsigned integer\t|255|\tN/A\t|0 to 254\t|N/A\n",
    "| FparExtra_QC\t|Extra detail Quality for  FPAR and LAI\t|Class Flag|\t8-bit unsigned integer|\t255\t|N/A\t|0 to 254\t|N/A\n",
    "|FparStdDev_500m|\tStandard deviation of  FPAR\t|Percent|\t8-bit unsigned integer|\t248 to 255\t|N/A|\t0 to 100\t|0.01\n",
    "|LaiStdDev_500m|\tStandard deviation of LAI\t|m²/m²|\t8-bit unsigned integer|\t248 to 255|\tN/A\t|0 to 100\t|0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a simple recipe for accessing a dataset and plotting it. All examples below will follow the same pattern.\n",
    "\n",
    "First, we use the `Modis` class in `geog0111.modis` to get the dataset. Recall from [024 Image display](024_Image_display) that many of these datasets are cached on the system for you. If it takes a long time to retrieve a dataset, it is probably because you are downloading it, rather than using a cached copy. If it is Wednesday afternoon UK time, you will not be able to download new datasets, and can only use cached copies, as the NASA server is down for maintenance.\n",
    "\n",
    "Notice that the LAI data have a valid range 0 to 100, and that a scale factor of 0.1 must be applied to the datas to interpret as LAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-05bdc63c9b44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# specify day of year (DOY) and year\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdata_MCD15A3H\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2019\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdoy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/nfs/cfs/home3/Uucfa6/ucfalew/geog0111/notebooks/geog0111/modis.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, year, doy, idict, month, day, step, fatal)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     '''\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0midict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midict\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_modis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdoy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfatal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfatal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;31m# for get_data, we only want required_sds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/cfs/home3/Uucfa6/ucfalew/geog0111/notebooks/geog0111/modis.py\u001b[0m in \u001b[0;36mget_modis\u001b[0;34m(self, year, doy, day, month, step, warp_args, dstNodata, fatal)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;31m#store for diagnostics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     kwargs = {'year': year, 'doy':doy,'day':day,'month':month,'step':step,\\\n\u001b[0;32m--> 338\u001b[0;31m               'warp_args':warp_args,'product': self.product, 'dstNodata':dstNodata, tile: self.tile}\n\u001b[0m\u001b[1;32m    339\u001b[0m     \u001b[0mmkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_from_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"modis\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tile' is not defined"
     ]
    }
   ],
   "source": [
    "from geog0111.modis import Modis\n",
    "#######################\n",
    "# specify what we want\n",
    "# in a dictionary\n",
    "#######################\n",
    "# UK tiles\n",
    "\n",
    "kwargs = {\n",
    "    'tile'      :    ['h17v03', 'h17v04', 'h18v03', 'h18v04'],\n",
    "    'product'   :    'MCD15A3H',\n",
    "    'sds'       :    'Lai_500m',\n",
    "}\n",
    "modis = Modis(**kwargs)\n",
    "# specify day of year (DOY) and year\n",
    "data_MCD15A3H = modis.get_data(2019,doy=1+4*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geog0111.im_display import im_display\n",
    "\n",
    "im_display(data_MCD15A3H,['Lai_500m'],x_size=16,y_size=8,vmax=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### masking\n",
    "\n",
    "We can see from the  [product specification page](https://lpdaac.usgs.gov/products/mcd15a3hv006/) for `MCD15A3H` that values above `100` for `Lai_500m` are invalid. In addition, a scale factor of 0.1 should be applied.\n",
    "\n",
    "\n",
    "We will learn more of this later, but for now, note that we can use code such as the following to apply the scaling factor and mask invalid numbers. We need to import the `numpy` package for this first (`import numpy as np`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geog0111.modis import Modis\n",
    "\n",
    "kwargs = {\n",
    "    'tile'      :    ['h17v03', 'h17v04', 'h18v03', 'h18v04'],\n",
    "    'product'   :    'MCD15A3H',\n",
    "    'sds'       :    'Lai_500m',\n",
    "}\n",
    "modis = Modis(**kwargs)\n",
    "\n",
    "# repull dataset\n",
    "data_MCD15A3H = modis.get_data(2019,doy=1+4*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# multiply by scale\n",
    "scale = 0.1\n",
    "ds = data_MCD15A3H['Lai_500m'] * scale\n",
    "# mask invalid by setting to \n",
    "ds[ds>100 * scale] = np.nan\n",
    "\n",
    "# load back into data_MCD15A3H\n",
    "data_MCD15A3H['Lai_500m'] = ds\n",
    "\n",
    "# plot\n",
    "im_display(data_MCD15A3H,['Lai_500m'],x_size=16,y_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset, being a measurement, is not spatially complete. This is because of clouds and other factors meaning that the algorithm to produce LAI could not run at that time. It is very common that you will find geospatial datasets have missing values. We will learn later on when and how we might fill these gaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Exercise 2: mask invalid data\n",
    "\n",
    "* write a function called `data_mask` that is given:\n",
    "    * a data dictionary\n",
    "    * a list of sds strings\n",
    "    * a list of scale factors\n",
    "    * a list of upper threshold values\n",
    "    * a list of lower threshold values\n",
    "  and returns the dictionary with the scaled and masked datasets \n",
    "  \n",
    "* plot both `Lai_500m` and `LaiStdDev_500m` side-by-side. You should apply appropriate scaling factors and masking as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "from geog0111.modis import Modis\n",
    "from geog0111.im_display import im_display\n",
    "import numpy as np\n",
    "\n",
    "def data_mask(data,sds,scales,uthresh,lthresh):\n",
    "    '''\n",
    "    given:\n",
    "    \n",
    "    data     : data dictionary\n",
    "    sds      : list of sds strings\n",
    "    scales   : list of scale factors\n",
    "    uthresh  : list of upper threshold values\n",
    "    lthresh  : list of upper threshold values\n",
    "    \n",
    "    return the dictionary with the scaled \n",
    "    and masked datasets \n",
    "    '''\n",
    "    for i,s in enumerate(sds):\n",
    "        scale = scales[i]\n",
    "        ds = data[s] * scale\n",
    "        # mask invalid by setting to \n",
    "        if uthresh[i] != None:\n",
    "            ds[ds>=uthresh[i] * scale] = np.nan\n",
    "        if lthresh[i] != None:\n",
    "            import pdb;pdb.set_trace()\n",
    "            ds[ds<=lthresh[i] * scale] = np.nan\n",
    "        # load back into data_MCD15A3H\n",
    "        data[s] = ds\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "# put the required SDS in the sds field of kwargs\n",
    "\n",
    "kwargs = {\n",
    "    'tile'      :    ['h17v03', 'h17v04', 'h18v03', 'h18v04'],\n",
    "    'product'   :    'MCD15A3H',\n",
    "    'sds'       :    ['Lai_500m','LaiStdDev_500m']\n",
    "}\n",
    "\n",
    "# get the data\n",
    "modis = Modis(**kwargs)\n",
    "# specify day of year (DOY) and year\n",
    "data_MCD15A3H = modis.get_data(2019,doy=1+4*10)\n",
    "\n",
    "sds     = kwargs['sds']\n",
    "scale   = [0.1, 0.1]\n",
    "uthresh = [100,100]\n",
    "lthresh = [None,None]\n",
    "\n",
    "data_MCD15A3H = data_mask(data_MCD15A3H,sds,scale,uthresh,lthresh)\n",
    "# plot with different vmax for the plots!\n",
    "im_display(data_MCD15A3H,kwargs['sds'],shape=(1,2),x_size=16,y_size=3,vmax=[5,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Burned area dataset `MCD64A1`\n",
    "\n",
    "We can use the same codes to access different MODIS datasets. For example the monthly [`MCD64A1`](https://lpdaac.usgs.gov/products/mcd64a1v006/) product:\n",
    "\n",
    "[![MCD15A3H](images/MCD15A3H.png)](https://lpdaac.usgs.gov/products/mcd64a1v006/)\n",
    "\n",
    "For the `Burn Date` field, values of -2 to 0 are invalid. We can visualise this with code as above, but first we need to get the day of year for the month we want. Recall from [023 Plotting](023_Plotting.ipynb#datetime) that we can use `datetime` for this. We do this by working out the difference between the day of the month in question and the 31st day of December for the previous year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "year = 2019\n",
    "day = 1\n",
    "for month in range(1,13):\n",
    "    doy = (datetime(year,month,day) - datetime(year-1,12,31)).days\n",
    "    print(f'1st of {month:<2d} is doy {doy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Exercise 3\n",
    "\n",
    "* write a function called `get_doy` that is given the year, month and day integer and returns the day of year\n",
    "* test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "from datetime import datetime\n",
    "\n",
    "def get_doy(year,month,day):\n",
    "    '''\n",
    "    function that is given \n",
    "    \n",
    "    the year \n",
    "    and month integer \n",
    "        \n",
    "    and returns the day of year\n",
    "    '''\n",
    "    doy = (datetime(year,month,day) - datetime(year-1,12,31)).days\n",
    "    return doy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "\n",
    "assert get_doy(2019,1,1) == 1\n",
    "assert get_doy(2019,2,1) == 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now simply need to encode any scale factors or invalidity thresholds, and we can plot the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geog0111.modis import Modis\n",
    "from geog0111.im_display import im_display\n",
    "from geog0111.data_mask import data_mask\n",
    "from geog0111.get_doy import get_doy\n",
    "\n",
    "# h22v10 is Madagascar\n",
    "kwargs = {\n",
    "    'tile'      :    ['h22v10'],\n",
    "    'product'   :    'MCD64A1',\n",
    "    'sds'       :    ['Burn Date'],\n",
    "}\n",
    "\n",
    "year  = 2019\n",
    "month = 6\n",
    "\n",
    "doy = get_doy(year,month,1)\n",
    "print(doy)\n",
    "# get the data\n",
    "modis = Modis(**kwargs)\n",
    "# specify day of year (DOY) and year\n",
    "data_MCD64A1 = modis.get_data(2019,doy=doy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale   = [1]\n",
    "uthresh = [200]\n",
    "lthresh = [0]\n",
    "\n",
    "data_MCD64A1 = data_mask(data_MCD64A1,kwargs['sds'],scale,uthresh,lthresh)\n",
    "\n",
    "# have to take sub-area to see anything here:\n",
    "# define row and column min/max with r=[1500,2000],c=[1000,1500]\n",
    "im_display(data_MCD64A1,kwargs['sds'],\\\n",
    "           x_size=10,y_size=8,\\\n",
    "           r=[1800,2000],c=[1000,1200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snow\n",
    "    \n",
    "There are two MODIS daily snow cover datasets: [`MOD10A1` and `MYD10A1`](https://modis-snow-ice.gsfc.nasa.gov/?c=MOD10A1) for data from the MODIS Terra and Aqua sensors, respectively. The field [`NDSI_Snow_Cover`](https://developers.google.com/earth-engine/datasets/catalog/MODIS_006_MOD10A1) has valid values in the range 0 to 100.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geog0111.modis import Modis\n",
    "from geog0111.im_display import im_display\n",
    "from geog0111.data_mask import data_mask\n",
    "from geog0111.get_doy import get_doy\n",
    "\n",
    "kwargs = {\n",
    "    'tile'      :    ['h19v03'],\n",
    "    'product'   :    'MOD10A1',\n",
    "    'sds'       :     ['NDSI_Snow_Cover']\n",
    "}\n",
    "\n",
    "# look in the winter\n",
    "year  = 2019\n",
    "month = 12\n",
    "day = 1\n",
    "\n",
    "scale   = [1]\n",
    "uthresh = [101]\n",
    "lthresh = [-1]\n",
    "sds     = kwargs['sds']\n",
    "\n",
    "doy = get_doy(year,month,day)\n",
    "print(doy)\n",
    "# get the data\n",
    "modis = Modis(**kwargs)\n",
    "# specify day of year (DOY) and year\n",
    "data_MOD10A1 = modis.get_data(2019,doy=doy)\n",
    "data_MOD10A1 = data_mask(data_MOD10A1,sds,scale,uthresh,lthresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to take sub-area to see anything here:\n",
    "# define row and column min/max with r=[1500,2000],c=[1000,1500]\n",
    "im_display(data_MOD10A1,kwargs['sds'],\\\n",
    "           x_size=10,y_size=8,colourmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Land Cover dataset `MCD12Q1`\n",
    "    \n",
    "One of the MODIS land cover products is `MCD12Q1`. We briefly examined this product in the previous session, but can take the chance now to explore it further. The datasets are yearly, given for `doy` 1. Details of the product can be found at the product page (`MCD12Q1`)[https://lpdaac.usgs.gov/products/mcd12q1v006/].\n",
    "\n",
    "We previously developed a code [`get_lc`](geog0111/plot_lc.py) to set up the colourmaps and plot the `LC_Type1` for a given year and set of tiles. This is the `Land Cover Type 1: Annual International Geosphere-Biosphere Programme (IGBP) classification`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geog0111.plot_lc import plot_lc\n",
    "from geog0111.modis import Modis\n",
    "# Madagascar\n",
    "year,tiles = 2018,['h22v10']\n",
    "\n",
    "# ensure tiles is a list\n",
    "kwargs = {\n",
    "    'tile'      :    list(tiles),\n",
    "    'product'   :    'MCD12Q1',\n",
    "    'sds'       :    ['LC_Type1']\n",
    "}\n",
    "# get the data\n",
    "modis = Modis(**kwargs)\n",
    "# specify day of year (DOY) and year\n",
    "data_MCD12Q1 = modis.get_data(year,doy=1)\n",
    "# the data we want here\n",
    "plot_lc(data_MCD12Q1['LC_Type1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Exercise 5\n",
    "\n",
    "* Explore the MODIS datasets in your own time, and get to know the datasets they contain, along with the scaling factors and other interpretation information. Note that if we have not already downloaded particular datasets into the cache, it  may take a short time for them to download and load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "# Explore!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In these notes, we have introduced the characteristics of MODIS data products, and learned how to specify, access, and display them for a number of datasets. You will have accessed a number of products under a number of conditions in the exercises, but you are encouraged to explore this further.\n",
    "\n",
    "The main item to do with using data products of this sort, that we haven't covered yet, is the interpretation of Quality Assurance (QA) data. This is often packed information into bits, and can be a little tricky at first. However, as with above, once you have a little familiarisation with a few cases, you will be able to apply this more widely.\n",
    "\n",
    "You should spend some time going through the various links to explore the different datasets, and try out the exercises above for various products. The familiarity you gain from this will help when it comes to building our own codes later on.\n",
    "\n",
    "Some MODIS datasets\n",
    "\n",
    "\n",
    "* [`MCD15A3H` LAI/fAPAR](https://lpdaac.usgs.gov/products/mcd15a3hv006/)\n",
    "* [`MCD64A1` Burned Area](https://lpdaac.usgs.gov/products/mcd64a1v006/)1\n",
    "* [`MOD10A1 / MYD10A1 Snow Products`](https://developers.google.com/earth-engine/datasets/catalog/MODIS_006_MOD10A1#bands)\n",
    "* [`Land Cover dataset MCD12Q1`](https://lpdaac.usgs.gov/products/mcd12q1v006/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[<img src=\"images/noun_post_2109127.svg\" width=\"50\" align='right'>](031_Numpy.ipynb)\n",
    "[<img src=\"images/noun_pre_2109128.svg\" width=\"50\" align='right'>](024_Image_display.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Chapter0_help.ipynb",
    "public": true
   },
   "id": ""
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:geog0111-geog0111]",
   "language": "python",
   "name": "conda-env-geog0111-geog0111-py"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": "1.1",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "207px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
